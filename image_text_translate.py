# -*- coding: utf-8 -*-
"""Image Text Translate.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hqAvkjMSDf1iceVujFxzYvcCYWkJYLzn
"""

!pip install tesseract pytesseract deep-translator Pillow

import cv2
import pytesseract
from PIL import Image
from deep_translator import GoogleTranslator

# Optional: If tesseract is not in PATH (Windows)
# pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"

def translate_image_text(
    image_path,
    target_language="en"
):
    # Load image
    img = cv2.imread(image_path)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # OCR: Extract text (auto language detection)
    extracted_text = pytesseract.image_to_string(gray, lang="eng+hin+spa+fra+deu+chi_sim+ara")

    if not extracted_text.strip():
        return "No text detected."

    # Translate text
    translated_text = GoogleTranslator(
        source="auto",
        target=target_language
    ).translate(extracted_text)

    return {
        "extracted_text": extracted_text,
        "translated_text": translated_text
    }


if __name__ == "__main__":
    image_path = "/content/xx.jpg"  # <-- your image
    result = translate_image_text(image_path, target_language="en")

    print("\n--- Extracted Text ---\n")
    print(result["extracted_text"])

    print("\n--- Translated Text ---\n")
    print(result["translated_text"])

import cv2
import pytesseract
from deep_translator import GoogleTranslator

# Optional (Windows only)
# pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"

# --------------------------------
# Language Options
# --------------------------------
LANGUAGES = {
    "en": "English",
    "hi": "Hindi",
    "es": "Spanish",
    "fr": "French",
    "de": "German",
    "ar": "Arabic",
    "zh-cn": "Chinese"
}

# --------------------------------
# OCR + Translation Function
# --------------------------------
def translate_image_text(image_path, target_language):
    # Load image safely
    img = cv2.imread(image_path)
    if img is None:
        return {"error": "âŒ Image not found or unsupported format."}

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # OCR (multiple languages)
    extracted_text = pytesseract.image_to_string(
        gray,
        lang="eng+hin+spa+fra+deu+chi_sim+ara"
    )

    if not extracted_text.strip():
        return {"error": "âš ï¸ No text detected in image."}

    # Translate
    translated_text = GoogleTranslator(
        source="auto",
        target=target_language
    ).translate(extracted_text)

    return {
        "extracted_text": extracted_text.strip(),
        "translated_text": translated_text.strip()
    }

# --------------------------------
# User Input
# --------------------------------
def ask_target_language():
    print("\nðŸŒ Choose target language:\n")
    for code, name in LANGUAGES.items():
        print(f"{code} â†’ {name}")

    choice = input("\nEnter language code: ").strip().lower()
    return choice if choice in LANGUAGES else "en"

# --------------------------------
# Main
# --------------------------------
if __name__ == "__main__":
    image_path = input("ðŸ“· Enter image path: ").strip()

    target_lang = ask_target_language()

    result = translate_image_text(image_path, target_lang)

    if "error" in result:
        print(result["error"])
    else:
        print("\nðŸ“ --- Extracted Text ---\n")
        print(result["extracted_text"])

        print("\nðŸŒ --- Translated Text ---\n")
        print(result["translated_text"])